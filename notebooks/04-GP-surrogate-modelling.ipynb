{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP surrogate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a surrogate model of EPANET's water quality solver using Gaussian Process (GP) regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "default_colors = plotly.colors.qualitative.Plotly\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ConstantKernel as C\n",
    "from bayesian_wq_calibration.epanet import build_model, sensor_model_id, epanet_simulator, set_reaction_parameters\n",
    "from bayesian_wq_calibration.calibration import decision_variables_to_dict, generate_samples\n",
    "from bayesian_wq_calibration.constants import TIMESERIES_DIR, RESULTS_DIR\n",
    "from bayesian_wq_calibration.data import bulk_temp_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load operational data for selected sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_period = 20 # 20 calibration events (as at 30 October 2024)\n",
    "wq_sensors_used = 'kiosk only' # 'kiosk only', 'kiosk + hydrant'\n",
    "demand_resolution = 'wwmd' # 'dma', 'wwmd'\n",
    "try:\n",
    "    flow_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-flow.csv\")\n",
    "    pressure_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-pressure.csv\")\n",
    "    wq_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-wq.csv\", low_memory=False)\n",
    "    cl_df = wq_df[wq_df['data_type'] == 'chlorine']\n",
    "except:\n",
    "    print(f\"Data period {data_period} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surrogate model data period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_days = 2\n",
    "\n",
    "n_total = len(flow_df['datetime'].unique())\n",
    "n_surrogate = surrogate_days * 24 * 4\n",
    "surrogate_range = range(n_surrogate)\n",
    "surrogate_datetime = flow_df['datetime'].unique()[list(surrogate_range)]\n",
    "total_range = range(n_total)\n",
    "total_datetime = flow_df['datetime'].unique()[list(total_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_coeff = -0.85 # day^-1 (from bottle tests)\n",
    "field_temp = wq_df[wq_df['data_type'] == 'temperature']['mean'].mean()\n",
    "bulk_coeff = bulk_temp_adjust(bulk_coeff, field_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wall decay grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see notebook `02-pipe-grouping-exploration.ipynb` for details on pipe groups\n",
    "grouping = 'material-age-velocity'\n",
    "\n",
    "# load ga results to get param_mean data\n",
    "ga_results_df = pd.read_excel(RESULTS_DIR / 'wq/ga_calibration.xlsx', sheet_name=grouping)\n",
    "ga_results_df = ga_results_df[(ga_results_df['data_period'] == data_period) & (ga_results_df['demand_resolution'] == demand_resolution) & (ga_results_df['wq_sensors_used'] == wq_sensors_used)]\n",
    "ga_results = ga_results_df[[col for col in ga_results_df.columns if col.startswith('G')]].values[0]\n",
    "\n",
    "grouping_data = {\n",
    "    'single': {\n",
    "        'param_group': ['G0'],\n",
    "        'param_bounds': [(-0.5, 0.0)],\n",
    "        'param_mean': ga_results\n",
    "    },\n",
    "    'material-only': {\n",
    "        'param_group': ['G0', 'G1'],\n",
    "        'param_bounds': [(-1.0, -0.01), (-0.5, -0.01), (-0.15, -0.01)],\n",
    "        'param_mean': ga_results\n",
    "    },\n",
    "    'material-age-diameter': {\n",
    "        'param_group': ['G0', 'G1', 'G2', 'G3', 'G4', 'G5'],\n",
    "        'param_bounds': [(-1.0, -0.01), (-1.0, -0.01), (-0.5, -0.01), (-0.5, -0.01), (-0.15, -0.01), (-0.15, -0.01)],\n",
    "        'param_mean': ga_results\n",
    "    },\n",
    "    'material-age-velocity': {\n",
    "        'param_group': ['G0', 'G1', 'G2', 'G3', 'G4', 'G5'],\n",
    "        'param_bounds': [(-1.0, -0.01), (-1.0, -0.01), (-0.5, -0.01), (-0.5, -0.01), (-0.15, -0.01), (-0.15, -0.01)],\n",
    "        'param_mean': ga_results\n",
    "    }\n",
    "}\n",
    "\n",
    "# extract parameter data\n",
    "param_data = grouping_data[grouping]\n",
    "param_group = param_data['param_group']\n",
    "param_bounds = param_data['param_bounds']\n",
    "param_mean = param_data['param_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surrogate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EPANET simulator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build water model using `wntr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = build_model(flow_df[flow_df['datetime'].isin(surrogate_datetime)], pressure_df[pressure_df['datetime'].isin(surrogate_datetime)], cl_df[cl_df['datetime'].isin(surrogate_datetime)], sim_type='chlorine', demand_resolution=demand_resolution, bulk_coeff=bulk_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean velocities (for 'material-velocity' grouping)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define simualtor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(cl_df, params, wn, grouping):\n",
    "    wall_coeffs = decision_variables_to_dict(grouping, params)\n",
    "    _wn = set_reaction_parameters(wn, grouping, wall_coeffs, bulk_coeff)\n",
    "    \n",
    "    sim_type = 'chlorine'\n",
    "    sim_results = epanet_simulator(_wn, sim_type, cl_df)\n",
    "    cl_sim = sim_results.chlorine\n",
    "    \n",
    "    sensor_data = sensor_model_id('wq')\n",
    "    cl_sim = cl_sim[sensor_data['model_id'].unique()]\n",
    "    name_mapping = sensor_data.set_index('model_id')['bwfl_id'].to_dict()\n",
    "    cl_sim = cl_sim.rename(columns=name_mapping)\n",
    "\n",
    "    cl_sim = cl_sim.T\n",
    "    cl_sim.columns = [f't_{idx+1}' for idx in range(cl_sim.shape[1])]\n",
    "\n",
    "    cl_sim = cl_sim.drop(index=['BW1', 'BW4'], errors='ignore') # remove inlet sensors\n",
    "    \n",
    "    return cl_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_simulator = simulator(cl_df[cl_df['datetime'].isin(surrogate_datetime)], param_mean, wn, grouping)\n",
    "sensor_names = cl_simulator.index.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Design of experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `generate_samples` function, which takes the following inputs:\n",
    "- `sampling_method` (default = latin hypercube sampling)\n",
    "- `dist_type` (default = truncated normal)\n",
    "- `rel_uncertainty` (default = 50% of parameter mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [10, 25, 50, 100, 200]\n",
    "n_samples_idx = 3\n",
    "\n",
    "X = generate_samples(param_mean, param_bounds, param_group, n_samples[n_samples_idx], sampling_method='lhs', dist_type='truncated normal', rel_uncertainty=0.75, plot=True)\n",
    "Y = np.array([\n",
    "    simulator(cl_df[cl_df['datetime'].isin(surrogate_datetime)], params, wn, grouping)\n",
    "    for params in X\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gausian process model training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training procedure using five-fold cross-validation and `scikit-learn` modules. The following kernel's can be used:\n",
    "- Radial basis function (RBF)\n",
    "- Matern\n",
    "- Rational quadratic\n",
    "\n",
    "Note: a separate GP is trained for each of the **7** sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'BW2' # 'BW2', 'BW3', 'BW5', 'BW6', 'BW7', 'BW9', 'BW12'\n",
    "s = np.where(sensor_names == sensor)[0][0]\n",
    "Y_s = Y[:, s, :].reshape(Y.shape[0], Y.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validate and test datasets\n",
    "n_0 = round(0.8*len(X))\n",
    "X_0 = X[:n_0, :]\n",
    "Y_s_0 = Y_s[:n_0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ConstantKernel as C\n",
    "\n",
    "def GPRegressor(kernel_type='RBF', nu=1.5, n_restarts=50, normalize_y=True):\n",
    "\n",
    "    if kernel_type == 'RBF':\n",
    "        kernel = C(1.0, (1e-1, 1e5)) * RBF(1.0, (1e-1, 1e10))\n",
    "    elif kernel_type == 'Matern':\n",
    "        kernel = C(1.0, (1e-1, 1e5)) * Matern(1.0, (1e-1, 1e10), 0.5)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown kernel type: {kernel_type}\")\n",
    "\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=n_restarts, normalize_y=normalize_y)\n",
    "    \n",
    "    return gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "kernel = 'RBF' # 'RBF', 'Matern'\n",
    "gp = GPRegressor(kernel_type=kernel, nu=0.5, n_restarts=50, normalize_y=True)\n",
    "\n",
    "# cross-validation loop\n",
    "hyperparameter_performance = []\n",
    "for fold, (train_idx, validate_idx) in enumerate(kf.split(X_0)):\n",
    "\n",
    "    X_train, X_validate = X_0[train_idx], X_0[validate_idx]\n",
    "    Y_train, Y_validate = Y_s_0[train_idx], Y_s_0[validate_idx]\n",
    "\n",
    "    gp.fit(X_train, Y_train)\n",
    "    Y_pred = gp.predict(X_validate)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(Y_validate, Y_pred))\n",
    "    mae = mean_absolute_error(Y_validate, Y_pred)\n",
    "    maxae = np.max(np.abs(Y_validate - Y_pred))\n",
    "    hyperparameter_performance.append({\n",
    "        \"fold\": fold + 1,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"maxae\": maxae,\n",
    "        \"length_scale\": gp.kernel_.get_params()['k2__length_scale'],\n",
    "        \"variance\": gp.kernel_.get_params()['k1__constant_value']\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {fold + 1} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, MaxAE: {maxae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train GP model with entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.fit(X_0, Y_s_0)\n",
    "print(gp.kernel_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X[n_0:]\n",
    "Y_s_1 = Y_s[n_0:, :]\n",
    "Y_pred, sigma = gp.predict(X_1, return_std=True)\n",
    "Y_upper = Y_pred + 1.96 * sigma\n",
    "Y_lower = Y_pred - 1.96 * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrics\n",
    "rmse = np.sqrt(np.mean((Y_s_1 - Y_pred) ** 2))\n",
    "print(f\"Root mean squared error: {rmse}\")\n",
    "mae = np.mean(np.abs(Y_s_1 - Y_pred))\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "maxae = np.max(np.abs(Y_s_1 - Y_pred))\n",
    "print(f\"Maximum absolute error: {maxae}\")\n",
    "r2 = gp.score(X_1, Y_s_1)\n",
    "print(f\"Kernel: {kernel}, r^2 Score: {r2}\")\n",
    "\n",
    "# parity plot of surrogate v. simulator\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=Y_s_1.flatten(),\n",
    "    y=Y_pred.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(size=6, opacity=0.6),\n",
    "))\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Simulator [mg/L]\",\n",
    "    yaxis_title=\"Surrogate [mg/L]\",\n",
    "    template=\"simple_white\",\n",
    "    width=550,\n",
    "    height=450\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# histogram plot of errors\n",
    "errors = (Y_s_1 - Y_pred).flatten()\n",
    "fig = go.Figure(data=[go.Histogram(x=errors, nbinsx=40)])\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Error [mg/L]\",\n",
    "    yaxis_title=f\"Frequency (n={len(errors)})\",\n",
    "    template=\"simple_white\",\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# cdf plot of absolute errors\n",
    "absolute_errors = np.abs(Y_s_1 - Y_pred).flatten()\n",
    "sorted_errors = np.sort(absolute_errors)\n",
    "cdf_values = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sorted_errors,\n",
    "    y=cdf_values,\n",
    "    mode='lines',\n",
    "))\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Absolute Error [mg/L]\",\n",
    "    yaxis_title=\"Cumulative distribution\",\n",
    "    template=\"simple_white\",\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "actual_data = Y_s_1\n",
    "predicted_data = Y_pred\n",
    "\n",
    "for exp_idx in range(len(X)-n_0):\n",
    "    color = default_colors[exp_idx % len(default_colors)]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=surrogate_datetime,\n",
    "            y=actual_data[exp_idx, :],\n",
    "            mode='lines',\n",
    "            name=f\"Simulator (Exp {exp_idx + 1})\",\n",
    "            line=dict(color=color, dash='solid'),\n",
    "            showlegend=True\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=surrogate_datetime,\n",
    "            y=predicted_data[exp_idx, :],\n",
    "            mode='lines',\n",
    "            name=f\"Surrogate (Exp {exp_idx + 1})\",\n",
    "            line=dict(color=color, dash='dash'),\n",
    "            showlegend=True\n",
    "        )\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Chlorine [mg/L]\",\n",
    "    rangemode=\"tozero\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=600,  # Fixed height since there's only one plot\n",
    "    template='simple_white',\n",
    "    legend_title_text='',\n",
    "    title=f\"GP model validation sensor {sensor}\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
