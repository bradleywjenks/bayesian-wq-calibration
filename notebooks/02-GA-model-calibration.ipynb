{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm model calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies a genetic algorithm to calibrate wall decay coefficients using data from each water quality sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "default_colors = plotly.colors.qualitative.Plotly\n",
    "from bayesian_wq_calibration.simulation import build_model, epanet_simulator, sensor_model_id\n",
    "from bayesian_wq_calibration.ga import evaluate, decision_variables_to_dict\n",
    "from bayesian_wq_calibration.constants import TIMESERIES_DIR, RESULTS_DIR\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and build water model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load operational data for selected sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating wall model decay coefficients for data period: 18...\n"
     ]
    }
   ],
   "source": [
    "data_period = 18 # 19 calibration events (as at 30 September 2024)\n",
    "try:\n",
    "    flow_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-flow.csv\")\n",
    "    pressure_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-pressure.csv\")\n",
    "    wq_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-wq.csv\", low_memory=False)\n",
    "    cl_df = wq_df[wq_df['data_type'] == 'chlorine']\n",
    "    print(f\"Calibrating wall model decay coefficients for data period: {data_period}...\")\n",
    "except:\n",
    "    print(f\"Data period {data_period} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sensing data into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(flow_df['datetime'].unique())\n",
    "n_train = 7 * 24 * 4\n",
    "\n",
    "train_range = range(n_train)\n",
    "train_datetime = flow_df['datetime'].unique()[list(train_range)]\n",
    "\n",
    "test_range = range(n_train, n_total)\n",
    "test_datetime = flow_df['datetime'].unique()[list(test_range)]\n",
    "\n",
    "total_range = range(n_total)\n",
    "total_datetime = flow_df['datetime'].unique()[list(total_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build water model via WNTR module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_train = build_model(flow_df[flow_df['datetime'].isin(train_datetime)], pressure_df[pressure_df['datetime'].isin(train_datetime)], cl_df[cl_df['datetime'].isin(train_datetime)], sim_type='chlorine', demand_resolution='wwmd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set grouping type and initialize wall decay coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = 'single'\n",
    "wall_coeffs_ub = -5.0\n",
    "wall_coeffs_lb = 0.0\n",
    "\n",
    "if grouping == 'single':\n",
    "    n_coeffs = 1\n",
    "elif grouping == 'material':\n",
    "    n_coeffs = 3\n",
    "elif grouping == 'material-diameter':\n",
    "    n_coeffs = 6\n",
    "elif grouping == 'roughness':\n",
    "    n_coeffs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize GA using DEAP module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "popsize = 25\n",
    "ngen = 50\n",
    "cxpb = 0.7\n",
    "mutpb = 0.2\n",
    "tournsize = 3\n",
    "hofsize = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up DEAP structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # minimize objective function\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, wall_coeffs_lb, wall_coeffs_ub)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=n_coeffs)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=tournsize)\n",
    "# pool = multiprocessing.Pool()\n",
    "# toolbox.register(\"map\", pool.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(wn, cl_df, grouping):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # preload data into the evaluation function\n",
    "    evaluation_function = partial(evaluate, wn=wn, cl_df=cl_df, grouping=grouping)\n",
    "    toolbox.register(\"evaluate\", evaluation_function)\n",
    "\n",
    "    # define statistics\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"max\", np.max)\n",
    "    stats.register(\"mean\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "\n",
    "    # initialize GA parameters\n",
    "    pop = toolbox.population(n=popsize)\n",
    "    hof = tools.HallOfFame(hofsize)\n",
    "    logbook = tools.Logbook()  # Initialize logbook\n",
    "\n",
    "    # set early stopping criteria\n",
    "    previous_best_fitness = np.inf\n",
    "    stagnant_gens = 0\n",
    "    max_stagnant_gens = 5\n",
    "\n",
    "    # run GA\n",
    "    for g in range(ngen):\n",
    "        \n",
    "        if g != 0:\n",
    "            pop = toolbox.select(pop, k=len(pop))\n",
    "            pop = algorithms.varAnd(pop, toolbox, cxpb=cxpb, mutpb=mutpb)\n",
    "        \n",
    "        # evaluate the individuals with invalid fitness\n",
    "        invalids = [ind for ind in pop if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalids)\n",
    "        for ind, fit in zip(invalids, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # update hall of fame and compile statistics\n",
    "        hof.update(pop)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g, nevals=len(invalids), **record)\n",
    "        if g == 0:\n",
    "            print(logbook.stream)\n",
    "        else:\n",
    "            print(logbook.stream.splitlines()[-1])\n",
    "\n",
    "        # check for improvement in fitness\n",
    "        current_best_fitness = hof[0].fitness.values[0]\n",
    "        if current_best_fitness < previous_best_fitness:\n",
    "            previous_best_fitness = current_best_fitness\n",
    "            stagnant_gens = 0\n",
    "        else:\n",
    "            stagnant_gens += 1\n",
    "    \n",
    "        # early stopping if no improvement\n",
    "        if stagnant_gens >= max_stagnant_gens:\n",
    "            print(f\"Terminating GA @ generation {g} due to solution quality stagnation. Best fitness: {current_best_fitness}\")\n",
    "            break\n",
    "        \n",
    "    cpu_time = time.time() - start_time \n",
    "    \n",
    "    return pop, logbook, hof, cpu_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tmax      \tmean     \tmin      \tnevals\n",
      "0  \t0.0675129\t0.0548498\t0.0176382\t25    \n",
      "gen\tmax      \tmean     \tmin      \tnevals\n",
      "0  \t0.0675129\t0.0548498\t0.0176382\t25    \n",
      "1  \t0.156976 \t0.0506367\t0.0171229\t21    \n",
      "gen\tmax      \tmean     \tmin      \tnevals\n",
      "0  \t0.0675129\t0.0548498\t0.0176382\t25    \n",
      "1  \t0.156976 \t0.0506367\t0.0171229\t21    \n",
      "2  \t0.272515 \t0.0426922\t0.0109062\t23    \n"
     ]
    }
   ],
   "source": [
    "pop, log, hof, cpu_time = main(wn_train, cl_df[cl_df['datetime'].isin(train_datetime)], grouping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train and test MSE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimized decay coefficients\n",
    "wall_coeffs_opt = decision_variables_to_dict(grouping, hof[0])\n",
    "\n",
    "# model simulation\n",
    "wn = build_model(flow_df, pressure_df, cl_df, sim_type='chlorine', demand_resolution='wwmd', grouping=grouping, wall_coeffs=wall_coeffs_opt)\n",
    "sim_results = epanet_simulator(wn, 'chlorine', cl_df)\n",
    "cl_sim = sim_results.chlorine\n",
    "\n",
    "# obtain simulated data @ sensor nodes\n",
    "sensor_data = sensor_model_id('wq')\n",
    "cl_sim = cl_sim[sensor_data['model_id'].unique()]\n",
    "name_mapping = sensor_data.set_index('model_id')['bwfl_id'].to_dict()\n",
    "cl_sim = cl_sim.rename(columns=name_mapping)\n",
    "bwfl_ids = [sensor for sensor in sensor_data['bwfl_id'].unique() if sensor not in ['BW1', 'BW4']]\n",
    "datetime = cl_df['datetime'].unique()\n",
    "\n",
    "# compute train mse\n",
    "train_mse = 0\n",
    "test_mse = 0\n",
    "for name in bwfl_ids:\n",
    "    sim = cl_sim[name].values\n",
    "    data = cl_df.loc[cl_df['bwfl_id'] == name, 'mean'].values\n",
    "    train_mask = ~np.isnan(sim) & ~np.isnan(data) & (np.arange(len(sim)) >= 96) & (np.arange(len(sim)) < n_train)\n",
    "    train_mse += (1 / (len(datetime) * len(bwfl_ids))) * np.sum((sim[train_mask] - data[train_mask]) ** 2)\n",
    "    test_mask = ~np.isnan(sim) & ~np.isnan(data) & (np.arange(len(sim)) >= n_train)\n",
    "    test_mse += (1 / (len(datetime) * len(bwfl_ids))) * np.sum((sim[test_mask] - data[test_mask]) ** 2)\n",
    "\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "assert train_mse == hof[0].fitness.values[0], \"GA train mse is not the same as a posteriori computation.\"\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save GA results to master spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "if save_results:\n",
    "    results_df = pd.read_excel(RESULTS_DIR / 'ga_calibration.xlsx', sheet_name=grouping)\n",
    "    \n",
    "    results_df.loc[results_df['data_period'] == data_period, 'train_mse'] = train_mse\n",
    "    results_df.loc[results_df['data_period'] == data_period, 'test_mse'] = test_mse\n",
    "    results_df.loc[results_df['data_period'] == data_period, 'cpu_time'] = cpu_time\n",
    "    results_df.loc[results_df['data_period'] == data_period, 'bulk_coeff'] = wn_train.options.reaction.bulk_coeff * 3600 * 24\n",
    "    for i, val in enumerate(wall_coeffs_opt):\n",
    "        results_df.loc[results_df['data_period'] == data_period, f\"wall_coeff_{i}\"] = val\n",
    "\n",
    "    with pd.ExcelWriter(RESULTS_DIR / 'ga_calibration.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "        results_df.to_excel(writer, sheet_name=grouping, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwfl_ids = cl_df['bwfl_id'].unique()\n",
    "\n",
    "subplot_titles = [f\"Chlorine time series @ {bwfl_id}\" for bwfl_id in bwfl_ids]\n",
    "fig = make_subplots(rows=len(bwfl_ids), cols=1, subplot_titles=subplot_titles)\n",
    "\n",
    "for idx, bwfl_id in enumerate(bwfl_ids):\n",
    "    # Filter data for current bwfl_id and datetime index >= 96\n",
    "    cl_df_subset = cl_df[(cl_df['bwfl_id'] == bwfl_id) & (cl_df.index >= 96)]\n",
    "    sim = cl_sim[bwfl_id].values[96:]\n",
    "\n",
    "    # sensor data\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cl_df_subset['datetime'],\n",
    "            y=cl_df_subset['mean'],\n",
    "            mode='lines',\n",
    "            name='sensor',  # Legend entry for Sensor series\n",
    "            line=dict(color='black'),\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=idx + 1, col=1\n",
    "    )\n",
    "    \n",
    "    # simulated data\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cl_df_subset['datetime'],\n",
    "            y=sim,\n",
    "            mode='lines',\n",
    "            name='simulated',\n",
    "            line=dict(color=default_colors[0]),\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=idx + 1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=450 * len(bwfl_ids),\n",
    "    template='simple_white',\n",
    "    legend_title_text='',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network residuals plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
