{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm model calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies a genetic algorithm to calibrate wall decay coefficients using data from each water quality sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "default_colors = plotly.colors.qualitative.Plotly\n",
    "from bayesian_wq_calibration.simulation import model_simulation, sensor_model_id\n",
    "from bayesian_wq_calibration.ga import evaluate\n",
    "from bayesian_wq_calibration.constants import TIMESERIES_DIR\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from functools import partial\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sensing data for selected sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating wall model decay coefficients for data period: 18...\n"
     ]
    }
   ],
   "source": [
    "data_period = 18 # 19 calibration events (as at 30 September 2024)\n",
    "try:\n",
    "    flow_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-flow.csv\")\n",
    "    pressure_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-pressure.csv\")\n",
    "    wq_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-wq.csv\", low_memory=False)\n",
    "    cl_df = wq_df[wq_df['data_type'] == 'chlorine']\n",
    "    print(f\"Calibrating wall model decay coefficients for data period: {data_period}...\")\n",
    "except:\n",
    "    print(f\"Data period {data_period} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sensing data into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(flow_df['datetime'].unique())\n",
    "n_train = 7 * 24 * 4\n",
    "\n",
    "train_range = range(n_train)\n",
    "train_datetime = flow_df['datetime'].unique()[list(train_range)]\n",
    "\n",
    "test_range = range(n_train, n_total)\n",
    "test_datetime = flow_df['datetime'].unique()[list(test_range)]\n",
    "\n",
    "total_range = range(n_total)\n",
    "total_datetime = flow_df['datetime'].unique()[list(total_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize GA using DEAP module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 25\n",
    "GENERATIONS = 50\n",
    "P_CROSSOVER = 0.7\n",
    "P_MUTATION = 0.2\n",
    "TOURNAMENT_SIZE = 3\n",
    "HALL_OF_FAME_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize wall decay coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = 'single'\n",
    "wall_coeffs_ub = -5.0\n",
    "wall_coeffs_lb = 0.0\n",
    "\n",
    "if grouping == 'single':\n",
    "    n_coeffs = 1\n",
    "elif grouping == 'diameter-based':\n",
    "    n_coeffs = 4\n",
    "elif grouping == 'roughness-based':\n",
    "    n_coeffs = 8\n",
    "elif grouping == 'material-based':\n",
    "    n_coeffs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up DEAP structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # minimize the objective function\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, wall_coeffs_lb, wall_coeffs_ub)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=n_coeffs)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)\n",
    "# pool = multiprocessing.Pool()\n",
    "# toolbox.register(\"map\", pool.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(flow_df, pressure_df, cl_df, grouping):\n",
    "\n",
    "    # use functools.partial to preload the current period's data into the evaluate function\n",
    "    evaluation_function = partial(evaluate, flow_df=flow_df, pressure_df=pressure_df, cl_df=cl_df, grouping=grouping)\n",
    "    toolbox.register(\"evaluate\", evaluation_function)\n",
    "\n",
    "    # initialize population\n",
    "    pop = toolbox.population(n=POPULATION_SIZE)\n",
    "\n",
    "    # define hall of fame to store the best individuals\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # define statistics\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # run the genetic algorithm for this data period\n",
    "    pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION, ngen=GENERATIONS, stats=stats, halloffame=hof, verbose=True)\n",
    "    \n",
    "    return pop, logbook, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pop, log, hof = main(flow_df[flow_df['datetime'].isin(train_datetime)], pressure_df[pressure_df['datetime'].isin(train_datetime)], cl_df[cl_df['datetime'].isin(train_datetime)], grouping)\n",
    "    print(\"Best individual is: %s\\nwith fitness: %s\" % (hof[0], hof[0].fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
