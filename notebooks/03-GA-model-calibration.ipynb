{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA model calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies a genetic algorithm (GA) to calibrate wall decay coefficients using data from each water quality sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "default_colors = plotly.colors.qualitative.Plotly\n",
    "from bayesian_wq_calibration.epanet import build_model, epanet_simulator, sensor_model_id\n",
    "from bayesian_wq_calibration.calibration import evaluate, decision_variables_to_dict\n",
    "from bayesian_wq_calibration.constants import TIMESERIES_DIR, RESULTS_DIR\n",
    "from bayesian_wq_calibration.plotting import plot_network, animate_network\n",
    "from bayesian_wq_calibration.data import bulk_temp_adjust\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and build water model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load operational data for selected sensing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_period = 16 # 20 calibration events (as at 30 October 2024)\n",
    "ga_run = True\n",
    "save_results = True\n",
    "wq_sensors_used = 'kiosk only' # 'kiosk only', 'kiosk + hydrant'\n",
    "\n",
    "try:\n",
    "    flow_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-flow.csv\")\n",
    "    pressure_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-pressure.csv\")\n",
    "    wq_df = pd.read_csv(TIMESERIES_DIR / f\"processed/{str(data_period).zfill(2)}-wq.csv\", low_memory=False)\n",
    "    cl_df = wq_df[wq_df['data_type'] == 'chlorine']\n",
    "\n",
    "    kiosk_ids = ['BW1', 'BW2', 'BW4', 'BW5', 'BW9', 'BW12']\n",
    "    bad_ids = ['BW7'] # remove BW7 from calibration\n",
    "    \n",
    "    if wq_sensors_used == 'kiosk only':\n",
    "        cl_df = cl_df[(cl_df['bwfl_id'].isin(kiosk_ids)) & (~cl_df['bwfl_id'].isin(bad_ids))]\n",
    "    else:\n",
    "        cl_df = cl_df[~cl_df['bwfl_id'].isin(bad_ids)]\n",
    "    \n",
    "    print(f\"Calibrating wall model decay coefficients for data period: {data_period}...\")\n",
    "    \n",
    "except:\n",
    "    print(f\"Data period {data_period} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sensing data into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(flow_df['datetime'].unique())\n",
    "n_train = 3 * 24 * 4 # 2 training days (day 1 discarded in wq simulation)\n",
    "\n",
    "train_range = range(n_train)\n",
    "train_datetime = flow_df['datetime'].unique()[list(train_range)]\n",
    "\n",
    "test_range = range(n_train, n_total)\n",
    "test_datetime = flow_df['datetime'].unique()[list(test_range)]\n",
    "\n",
    "total_range = range(n_total)\n",
    "total_datetime = flow_df['datetime'].unique()[list(total_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build water model via WNTR module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_resolution = 'wwmd'\n",
    "bulk_coeff = -0.85 # day^-1 (from bottle tests)\n",
    "field_temp = wq_df[wq_df['data_type'] == 'temperature']['mean'].mean()\n",
    "bulk_coeff = bulk_temp_adjust(bulk_coeff, field_temp)\n",
    "\n",
    "wn_train = build_model(flow_df[flow_df['datetime'].isin(train_datetime)], pressure_df[pressure_df['datetime'].isin(train_datetime)], cl_df[cl_df['datetime'].isin(train_datetime)], sim_type='chlorine', demand_resolution=demand_resolution, bulk_coeff=bulk_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set grouping type and initialize decay coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see notebook `02-pipe-grouping-exploration.ipynb` for details on pipe groups\n",
    "grouping = 'material-age-velocity'\n",
    "\n",
    "if grouping == 'single':\n",
    "    param_bounds = [(-1.0, -0.01)] # single wall decay coefficient\n",
    "elif grouping == 'material-only':\n",
    "    param_bounds = [(-1.0, -0.01), (-0.5, -0.01), (-0.15, -0.01)] # variable order: M0, M1, M2\n",
    "elif grouping == 'material-age-diameter':\n",
    "    param_bounds = [(-1.0, -0.01), (-1.0, -0.01), (-0.5, -0.01), (-0.5, -0.01), (-0.2, -0.01)] # variable order: G0, G1, G2, G3, G4\n",
    "elif grouping == 'material-age-velocity':\n",
    "    param_bounds = [(-1.0, -0.01), (-1.0, -0.01), (-0.5, -0.01), (-0.5, -0.01), (-0.2, -0.01)] # variable order: G0, G1, G2, G3, G4\n",
    "    \n",
    "n_params = len(param_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_bounds(individual, param_bounds):\n",
    "    for i, (lb, ub) in enumerate(param_bounds):\n",
    "        if individual[i] < lb:\n",
    "            individual[i] = lb\n",
    "        elif individual[i] > ub:\n",
    "            individual[i] = ub\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize GA using DEAP module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popsize = 50\n",
    "ngen = 50\n",
    "cxpb = 0.7\n",
    "mutpb = 0.1\n",
    "tournsize = 3\n",
    "hofsize = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up DEAP structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # minimize objective function\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "def generate_individual():\n",
    "    return [random.uniform(lb, ub) for lb, ub in param_bounds]\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, generate_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "# toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=tournsize)\n",
    "# pool = multiprocessing.Pool()\n",
    "# toolbox.register(\"map\", pool.map)\n",
    "\n",
    "low = [b[0] for b in param_bounds]\n",
    "up = [b[1] for b in param_bounds]\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=low, up=up, eta=20, indpb=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(wn, cl_df, grouping):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # preload data into the evaluation function\n",
    "    evaluation_function = partial(evaluate, wn=wn, cl_df=cl_df, grouping=grouping)\n",
    "    toolbox.register(\"evaluate\", evaluation_function)\n",
    "\n",
    "    # define statistics\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"max\", np.max)\n",
    "    stats.register(\"mean\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "\n",
    "    # initialize GA parameters\n",
    "    pop = toolbox.population(n=popsize)\n",
    "    hof = tools.HallOfFame(hofsize)\n",
    "    logbook = tools.Logbook()\n",
    "\n",
    "    # set early stopping criteria\n",
    "    stagnant_gens = 0\n",
    "    max_stagnant_gens = 5\n",
    "    threshold = 1e-3 \n",
    "\n",
    "    # run GA\n",
    "    for g in range(ngen):\n",
    "        \n",
    "        if g != 0:\n",
    "            pop = toolbox.select(pop, k=len(pop))\n",
    "            pop = algorithms.varAnd(pop, toolbox, cxpb=cxpb, mutpb=mutpb)\n",
    "            \n",
    "            for ind in pop:\n",
    "                enforce_bounds(ind, param_bounds)\n",
    "        \n",
    "        # evaluate the individuals with invalid fitness\n",
    "        invalids = [ind for ind in pop if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalids)\n",
    "        for ind, fit in zip(invalids, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # update hall of fame and compile statistics\n",
    "        hof.update(pop)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g, nevals=len(invalids), **record)\n",
    "        # if g == 0:\n",
    "        #     print(logbook.stream)\n",
    "        # else:\n",
    "        #     print(logbook.stream.splitlines()[-1])\n",
    "\n",
    "        # retrieve current best fitness from hall of fame\n",
    "        current_best_fitness = hof[0].fitness.values[0]\n",
    "        \n",
    "        # initialize previous_best_fitness at the end of the first generation's evaluation\n",
    "        if g == 0:\n",
    "            previous_best_fitness = current_best_fitness\n",
    "\n",
    "        # calculate percent difference for early stopping\n",
    "        percent_difference = abs(current_best_fitness - previous_best_fitness) / max(abs(previous_best_fitness), 1e-6)\n",
    "        print(f\"Gen {g}: Current best fitness = {current_best_fitness}, Previous best fitness = {previous_best_fitness}, Percent difference = {percent_difference}, Stagnant generation = {stagnant_gens}.\")\n",
    "\n",
    "        # check if improvement exceeds threshold\n",
    "        if percent_difference > threshold:\n",
    "            previous_best_fitness = current_best_fitness\n",
    "            stagnant_gens = 0\n",
    "        else:\n",
    "            stagnant_gens += 1\n",
    "    \n",
    "        # early stopping if no improvement\n",
    "        if stagnant_gens >= max_stagnant_gens:\n",
    "            print(f\"Terminating GA @ generation {g} due to solution quality stagnation. Best fitness: {current_best_fitness}\")\n",
    "            break\n",
    "        \n",
    "    cpu_time = time.time() - start_time \n",
    "    \n",
    "    return pop, logbook, hof, cpu_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ga_run:\n",
    "    pop, log, hof, cpu_time = main(wn_train, cl_df[cl_df['datetime'].isin(train_datetime)], grouping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train and test MSE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimized decay coefficients\n",
    "if ga_run:\n",
    "    wall_coeffs_opt = decision_variables_to_dict(grouping, hof[0])\n",
    "    print(wall_coeffs_opt)\n",
    "else:\n",
    "    results_df = pd.read_excel(RESULTS_DIR / 'wq/ga_calibration.xlsx', sheet_name=grouping)\n",
    "    selected_row = results_df[results_df['data_period'] == data_period]\n",
    "    wall_coeff_columns = [col for col in results_df.columns if col.startswith('G')]\n",
    "    wall_coeffs_opt_vector = selected_row[wall_coeff_columns].values.flatten()\n",
    "    wall_coeffs_opt = decision_variables_to_dict(grouping, wall_coeffs_opt_vector)\n",
    "    print(wall_coeffs_opt)\n",
    "\n",
    "# model simulation\n",
    "wn = build_model(flow_df, pressure_df, cl_df, sim_type='chlorine', demand_resolution='wwmd', grouping=grouping, wall_coeffs=wall_coeffs_opt)\n",
    "sim_results = epanet_simulator(wn, 'chlorine', cl_df)\n",
    "cl_sim = sim_results.chlorine\n",
    "\n",
    "# obtain simulated data @ sensor nodes\n",
    "sensor_data = sensor_model_id('wq')\n",
    "cl_sim_sensor = cl_sim[sensor_data['model_id'].unique()]\n",
    "name_mapping = sensor_data.set_index('model_id')['bwfl_id'].to_dict()\n",
    "cl_sim_sensor = cl_sim_sensor.rename(columns=name_mapping)\n",
    "cl_df_bwfl_ids = cl_df['bwfl_id'].unique()\n",
    "bwfl_ids = [sensor for sensor in sensor_data['bwfl_id'].unique() if sensor in cl_df_bwfl_ids and sensor not in ['BW1', 'BW4']]\n",
    "datetime = cl_df['datetime'].unique()\n",
    "\n",
    "# compute train mse\n",
    "train_mse = 0\n",
    "test_mse = 0\n",
    "for name in bwfl_ids:\n",
    "    sim = cl_sim_sensor[name].values\n",
    "    data = cl_df.loc[cl_df['bwfl_id'] == name, 'mean'].values\n",
    "    train_mask = ~np.isnan(sim) & ~np.isnan(data) & (np.arange(len(sim)) >= 96) & (np.arange(len(sim)) < n_train)\n",
    "    train_mse += (1 / (len(datetime[96:n_train]) * len(bwfl_ids))) * np.sum((sim[train_mask] - data[train_mask]) ** 2)\n",
    "    test_mask = ~np.isnan(sim) & ~np.isnan(data) & (np.arange(len(sim)) >= n_train)\n",
    "    test_mse += (1 / (len(datetime[n_train:]) * len(bwfl_ids))) * np.sum((sim[test_mask] - data[test_mask]) ** 2)\n",
    "\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "# assert train_mse == hof[0].fitness.values[0], \"GA train mse is not the same as a posteriori computation.\"\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save GA results to master spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    results_df = pd.read_excel(RESULTS_DIR / 'wq/ga_calibration.xlsx', sheet_name=grouping)\n",
    "\n",
    "    new_row = {\n",
    "        'data_period': data_period,\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'cpu_time': cpu_time,\n",
    "        'demand_resolution': demand_resolution,\n",
    "        'bulk_coeff': wn_train.options.reaction.bulk_coeff * 3600 * 24,\n",
    "        'wq_sensors_used': wq_sensors_used,\n",
    "    }\n",
    "    for key, val in wall_coeffs_opt.items():\n",
    "        new_row[key] = val\n",
    "        \n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "\n",
    "    with pd.ExcelWriter(RESULTS_DIR / 'wq/ga_calibration.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "        results_df.to_excel(writer, sheet_name=grouping, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bwfl_ids = [bwfl_id for bwfl_id in wq_df['bwfl_id'].unique() if bwfl_id not in ['BW1', 'BW4']]\n",
    "bwfl_ids = ['BW1', 'BW2', 'BW3', 'BW4', 'BW5', 'BW6', 'BW7', 'BW9', 'BW12']\n",
    "subplot_titles = [f\"Chlorine time series @ {bwfl_id}\" for bwfl_id in bwfl_ids]\n",
    "fig = make_subplots(rows=len(bwfl_ids), cols=1, subplot_titles=subplot_titles)\n",
    "\n",
    "y_max = 1.0\n",
    "\n",
    "for idx, bwfl_id in enumerate(bwfl_ids): \n",
    "    data = wq_df[(wq_df['bwfl_id'] == bwfl_id) & (wq_df['data_type'] == 'chlorine')]\n",
    "    sim = cl_sim_sensor[bwfl_id].values\n",
    "    show_legend = (idx == 0)\n",
    "\n",
    "    # sensor data\n",
    "    if wq_sensors_used == 'kiosk only':\n",
    "        if bwfl_id in ['BW3', 'BW6', 'BW7']:\n",
    "            dash = 'dot'\n",
    "        else:\n",
    "            dash = 'solid'\n",
    "    else:\n",
    "        dash = 'solid'\n",
    "            \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data['datetime'][96:],\n",
    "            y=data['mean'][96:],\n",
    "            mode='lines',\n",
    "            name='actual',\n",
    "            line=dict(color='black', dash=dash),\n",
    "            showlegend=show_legend\n",
    "        ),\n",
    "        row=idx + 1, col=1\n",
    "    )\n",
    "    \n",
    "    # simulated data\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data['datetime'][96:],\n",
    "            y=sim[96:],\n",
    "            mode='lines',\n",
    "            name='model',\n",
    "            line=dict(color=default_colors[1]),\n",
    "            showlegend=show_legend\n",
    "        ),\n",
    "        row=idx + 1, col=1\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"Chlorine [mg/L]\", rangemode=\"tozero\", range=[0, y_max], row=idx + 1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=450 * len(bwfl_ids),\n",
    "    template='simple_white',\n",
    "    legend_title_text='',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwfl_ids = [bwfl_id for bwfl_id in cl_df['bwfl_id'].unique() if bwfl_id not in ['BW1', 'BW4']]\n",
    "\n",
    "residuals_df = pd.DataFrame(columns=['bwfl_id', 'Residuals', 'Dataset'])\n",
    "for bwfl_id in bwfl_ids:\n",
    "    data = cl_df[cl_df['bwfl_id'] == bwfl_id]\n",
    "    sim = cl_sim_sensor[bwfl_id].values\n",
    "    train_residuals = sim[96:n_train] - data['mean'].values[96:n_train]\n",
    "    test_residuals = sim[n_train:] - data['mean'].values[n_train:]\n",
    "    \n",
    "    residuals_df = pd.concat([\n",
    "        residuals_df,\n",
    "        pd.DataFrame({'bwfl_id': bwfl_id, 'Residuals': train_residuals, 'Dataset': 'Train'}),\n",
    "        pd.DataFrame({'bwfl_id': bwfl_id, 'Residuals': test_residuals, 'Dataset': 'Test'})\n",
    "    ], ignore_index=True)\n",
    "\n",
    "fig = px.box(residuals_df, x='bwfl_id', y='Residuals', color='Dataset',\n",
    "             labels={'bwfl_id': 'BWFL ID', 'Residuals': 'Residuals'},\n",
    "             points='outliers')\n",
    "\n",
    "fig.update_layout(\n",
    "    height=450,\n",
    "    xaxis_title='',\n",
    "    yaxis_title='Chlorine residual [mg/L]',\n",
    "    template='simple_white',\n",
    "    legend_title_text='',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network residuals plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format simulation results\n",
    "column_names_cl = [f'cl_{t+1}' for t in range(cl_sim.shape[0])]\n",
    "cl_sim_T = cl_sim.T\n",
    "cl_sim_T.columns = column_names_cl\n",
    "cl_sim_T = cl_sim_T.reset_index().rename(columns={'name': 'node_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot network\n",
    "t = 96 * 2 + (4 * 4)\n",
    "plot_network(vals=cl_sim_T, val_type='chlorine', t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # play network animation\n",
    "# datetime = cl_df['datetime'].unique()\n",
    "# hourly_timesteps = list(range(96 * 2, len(datetime), 4))\n",
    "# animate_network(cl_sim_T, datetime, timesteps=hourly_timesteps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
